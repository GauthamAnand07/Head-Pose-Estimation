{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ictBAsdgufv5"
      },
      "outputs": [],
      "source": [
        "!pip -q install mediapipe opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVX7TlCysitR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time\n",
        "from google.colab import files, drive\n",
        "from IPython.display import display, Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypU_uH0dwwoZ"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the folder path in Google Drive\n",
        "output_folder = '/content/drive/MyDrive/HeadPoseFrames'\n",
        "os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0lwpk71ujJv"
      },
      "outputs": [],
      "source": [
        "# Step 1: Upload the video file\n",
        "# uploaded = files.upload()  # Manually upload the video file in Colab\n",
        "video_path = \"/content/b.mp4\"  # Get the path of the uploaded video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z_konPyun8f"
      },
      "outputs": [],
      "source": [
        "# Initialize MediaPipe FaceMesh\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# Initialize drawing utilities\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "drawing_spec = mp_drawing.DrawingSpec(color=(128, 0, 128), thickness=2, circle_radius=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx0fqZ1gusEp"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load the video file\n",
        "cap = cv2.VideoCapture(video_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jw1JoBwYuuok",
        "outputId": "fd45a2c2-f98d-4c52-bb00-5c13134a7f02"
      },
      "outputs": [],
      "source": [
        "# Step 3: Process and display each frame\n",
        "frame_number = 0\n",
        "while cap.isOpened():\n",
        "    success, image = cap.read()\n",
        "    if not success:\n",
        "        break  # Exit if the video has ended\n",
        "\n",
        "    start = time.time()  # Record start time for FPS calculation\n",
        "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
        "    image.flags.writeable = False\n",
        "    results = face_mesh.process(image)\n",
        "    image.flags.writeable = True\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    img_h, img_w, img_c = image.shape\n",
        "    face_2d = []\n",
        "    face_3d = []\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            for idx, lm in enumerate(face_landmarks.landmark):\n",
        "                if idx in {33, 263, 1, 61, 291, 199}:\n",
        "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
        "                    face_2d.append([x, y])\n",
        "                    face_3d.append([x, y, lm.z])\n",
        "\n",
        "                    if idx == 1:  # Nose landmark\n",
        "                        nose_2d = (lm.x * img_w, lm.y * img_h)\n",
        "                        nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
        "\n",
        "            face_2d = np.array(face_2d, dtype=np.float64)\n",
        "            face_3d = np.array(face_3d, dtype=np.float64)\n",
        "\n",
        "            focal_length = 1 * img_w\n",
        "            cam_matrix = np.array([[focal_length, 0, img_w / 2],\n",
        "                                   [0, focal_length, img_h / 2],\n",
        "                                   [0, 0, 1]])\n",
        "            distortion_matrix = np.zeros((4, 1), dtype=np.float64)\n",
        "\n",
        "            success, rotation_vec, translation_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, distortion_matrix)\n",
        "            rmat, _ = cv2.Rodrigues(rotation_vec)\n",
        "            angles, _, _, _, _, _ = cv2.RQDecomp3x3(rmat)\n",
        "\n",
        "            # Check the length of angles before unpacking\n",
        "            if len(angles) == 3:\n",
        "                x, y, z = [angle * 360 for angle in angles]  # Convert each to degrees\n",
        "            else:\n",
        "                x, y, z = 0, 0, 0  # Default to zero if angles has an unexpected structure\n",
        "\n",
        "\n",
        "            if y < -8:\n",
        "                text = \"Looking Left\"\n",
        "            elif y > 8:\n",
        "                text = \"Looking Right\"\n",
        "            elif x < -10:\n",
        "                text = \"Looking Down\"\n",
        "            elif x > 10:\n",
        "                text = \"Looking Up\"\n",
        "            else:\n",
        "                text = \"Forward\"\n",
        "\n",
        "            nose_3d_projection, _ = cv2.projectPoints(nose_3d, rotation_vec, translation_vec, cam_matrix, distortion_matrix)\n",
        "            p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
        "            p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\n",
        "            cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
        "\n",
        "            cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
        "            cv2.putText(image, f\"x: {np.round(x, 2)}\", (500, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "            cv2.putText(image, f\"y: {np.round(y, 2)}\", (500, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "            cv2.putText(image, f\"z: {np.round(z, 2)}\", (500, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "            mp_drawing.draw_landmarks(image=image,\n",
        "                                      landmark_list=face_landmarks,\n",
        "                                      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                                      landmark_drawing_spec=drawing_spec,\n",
        "                                      connection_drawing_spec=drawing_spec)\n",
        "\n",
        "        end = time.time()\n",
        "        totalTime = end - start\n",
        "\n",
        "# Save each frame as an image file to Google Drive\n",
        "    frame_output_path = os.path.join(output_folder, f\"frame_{frame_number}.jpg\")\n",
        "    cv2.imwrite(frame_output_path, image)\n",
        "    frame_number += 1\n",
        "\n",
        "    # Optional: Limit frame processing to first 100 frames for efficiency during testing\n",
        "#\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM92oBANuvZa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}